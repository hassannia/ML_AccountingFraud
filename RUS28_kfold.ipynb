{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4bc0257",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os.path import isfile\n",
    "from extra_codes import calc_vif\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from statsmodels.tsa.stattools import kpss\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "class ML_Fraud:\n",
    "    __version__='1.0.5'\n",
    "    def __init__(self,sample_start=1991,test_sample=range(2001,2011),\n",
    "                 OOS_per=1,OOS_gap=0,sampling='expanding',adjust_serial=True,\n",
    "                 cv_type='kfold',temp_year=1,cv_flag=False,cv_k=10,write=True,IS_per=10):\n",
    "\n",
    "        if isfile('FraudDB2020.csv')==False:\n",
    "            df=pd.DataFrame()\n",
    "            for s in range(1,5):\n",
    "                fl_name='FraudDB2020_Part'+str(s)+'.csv'\n",
    "                new_df=pd.read_csv(fl_name)\n",
    "                df=df.append(new_df)\n",
    "            df.to_csv('FraudDB2020.csv',index=False)\n",
    "            \n",
    "        df=pd.read_csv('FraudDB2020.csv')\n",
    "        self.df=df\n",
    "        self.ss=sample_start\n",
    "        self.se=np.max(df.fyear)\n",
    "        self.ts=test_sample\n",
    "        self.cv_t=cv_type\n",
    "        self.cv=cv_flag\n",
    "        self.cv_k=cv_k\n",
    "        self.cv_t_y=temp_year\n",
    "        \n",
    "        sampling_set=['expanding','rolling']\n",
    "        if sampling in sampling_set:\n",
    "            pass\n",
    "        else:\n",
    "            raise ValueError('Invalid sampling choice. Permitted options are \"expanding\" and \"rolling\"')\n",
    "        \n",
    "        self.sa=sampling\n",
    "        self.w=write\n",
    "        self.ip=IS_per\n",
    "        self.op=OOS_per\n",
    "        self.og=OOS_gap\n",
    "        self.a_s=adjust_serial\n",
    "        print('Module initiated successfully ...')\n",
    "        #The dir() function returns all properties and methods of the specified object, without the values.\n",
    "        list_methods=dir(self)\n",
    "        # .any: It checks for any element satisfying a condition and returns a True in case it finds any one element.\n",
    "        reduced_methods=[item+'()' for item in list_methods if any(['analy' in item,'compare' in item,item=='sumstats'])]\n",
    "        #string.join(iterable)\n",
    "        print('Procedures are: '+'; '.join(reduced_methods)) \n",
    "    \n",
    "    \n",
    "    def analyse_raw(self, C_FN=30,C_FP=1):\n",
    "        \"\"\"\n",
    "        This code replicates the RUSBoost model of Bao et al (2020).\n",
    "        Skipping cross-validation sets the number of estimators to 1000.\n",
    "\n",
    "        Parameters:\n",
    "            – C_FN: Cost of a False Negative for ECM\n",
    "            – C_FP: Cost of a False Positive for ECM\n",
    "        \n",
    "        \n",
    "        Predictive models:\n",
    "            – RUSBoost based on Scikit module\n",
    "        Outputs: \n",
    "        Main results are stored in the table variable \"perf_tbl_general\" written into\n",
    "        2 csv files: time period 2001-2010 and 2003-2008\n",
    "\n",
    "        Steps:\n",
    "            1. Cross-validate to find optimal hyperparameters.\n",
    "            2. Estimating the performance for each OOS period.\n",
    "\n",
    "        Warnings: \n",
    "            – Running this code can take up to 10 mins when CV is skipped. \n",
    "            These figures are estimates based on a MacBook Pro 2021.\n",
    "            \n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        from sklearn.tree import DecisionTreeClassifier\n",
    "        from sklearn.model_selection import GridSearchCV\n",
    "        from datetime import datetime\n",
    "        from imblearn.ensemble import RUSBoostClassifier\n",
    "        from sklearn.metrics import roc_auc_score\n",
    "        from extra_codes import ndcg_k\n",
    "        from sklearn.preprocessing import MinMaxScaler\n",
    "        \n",
    "        t0=datetime.now()\n",
    "\n",
    "        ## setting the parameters\n",
    "        \n",
    "        # IS_period=self.ip since the Bao approach is an expanding one\n",
    "        k_fold=self.cv_k\n",
    "        OOS_period=self.op # 1 year ahead prediction\n",
    "        OOS_gap=self.og # Gap between training and testing period\n",
    "        start_OOS_year=self.ts[0]\n",
    "        end_OOS_year=self.ts[-1]\n",
    "        sample_start=self.ss\n",
    "        adjust_serial=self.a_s\n",
    "        cv_type=self.cv_t\n",
    "        cross_val=self.cv\n",
    "        temp_year=self.cv_t_y\n",
    "        case_window=self.sa\n",
    "        fraud_df=self.df.copy(deep=True)\n",
    "        write=self.w\n",
    "\n",
    "        reduced_tbl_1=fraud_df.iloc[:,[0,1,3,7,8]]\n",
    "        reduced_tbl_2=fraud_df.iloc[:,9:-14]\n",
    "        reduced_tblset=[reduced_tbl_1,reduced_tbl_2]\n",
    "        reduced_tbl=pd.concat(reduced_tblset,axis=1)\n",
    "        reduced_tbl=reduced_tbl.reset_index(drop=True)\n",
    "\n",
    "        range_oos=range(start_OOS_year,end_OOS_year+1)#2001-2010\n",
    "        #1991-2000\n",
    "        tbl_year_IS_CV=reduced_tbl.loc[np.logical_and(reduced_tbl.fyear<start_OOS_year,\\\n",
    "                                                   reduced_tbl.fyear>=sample_start)]\n",
    "        tbl_year_IS_CV=tbl_year_IS_CV.reset_index(drop=True)\n",
    "        misstate_firms=np.unique(tbl_year_IS_CV.gvkey[tbl_year_IS_CV.AAER_DUMMY==1])\n",
    "\n",
    "        X_CV=tbl_year_IS_CV.iloc[:,-28:]\n",
    "\n",
    "        Y_CV=tbl_year_IS_CV.AAER_DUMMY\n",
    "\n",
    "        P_f=np.sum(Y_CV==1)/len(Y_CV)\n",
    "        P_nf=1-P_f\n",
    "        \n",
    "        n_opt_rus=200\n",
    "        r_opt_rus=1e-5\n",
    "        \n",
    "        # Setting as proposed in Bao et al (2020)\n",
    "        #testing OOS period with the fine tuned hyperparametres \n",
    "        roc_rusboost=np.zeros(len(range_oos))\n",
    "        specificity_rusboost=np.zeros(len(range_oos))\n",
    "        sensitivity_OOS_rusboost=np.zeros(len(range_oos))\n",
    "        precision_rusboost=np.zeros(len(range_oos))\n",
    "        sensitivity_OOS_rusboost1=np.zeros(len(range_oos))\n",
    "        specificity_OOS_rusboost1=np.zeros(len(range_oos))\n",
    "        precision_rusboost1=np.zeros(len(range_oos))\n",
    "        ndcg_rusboost1=np.zeros(len(range_oos))\n",
    "        ecm_rusboost1=np.zeros(len(range_oos))\n",
    "\n",
    "        m=0\n",
    "\n",
    "        for yr in range_oos:\n",
    "            t1=datetime.now()\n",
    "            \n",
    "            year_start_IS=sample_start\n",
    "            #1991-2000\n",
    "            tbl_year_IS=reduced_tbl.loc[np.logical_and(reduced_tbl.fyear<yr-OOS_gap,\\\n",
    "                                                       reduced_tbl.fyear>=year_start_IS)]\n",
    "            tbl_year_IS=tbl_year_IS.reset_index(drop=True)\n",
    "            misstate_firms=np.unique(tbl_year_IS.gvkey[tbl_year_IS.AAER_DUMMY==1])\n",
    "            #2001\n",
    "            tbl_year_OOS=reduced_tbl.loc[reduced_tbl.fyear==yr]\n",
    "            \n",
    "            if adjust_serial==True:\n",
    "                ok_index=np.zeros(tbl_year_OOS.shape[0])\n",
    "                for s in range(0,tbl_year_OOS.shape[0]):\n",
    "                    if not tbl_year_OOS.iloc[s,1] in misstate_firms:\n",
    "                        ok_index[s]=True\n",
    "                \n",
    "            else:\n",
    "                ok_index=np.ones(tbl_year_OOS.shape[0]).astype(bool)\n",
    "                \n",
    "            \n",
    "            tbl_year_OOS=tbl_year_OOS.iloc[ok_index==True,:]\n",
    "            tbl_year_OOS=tbl_year_OOS.reset_index(drop=True)\n",
    "            \n",
    "            X=tbl_year_IS.iloc[:,-28:]\n",
    "\n",
    "            Y=tbl_year_IS.AAER_DUMMY\n",
    "            \n",
    "            X_OOS=tbl_year_OOS.iloc[:,-28:]\n",
    "            \n",
    "            Y_OOS=tbl_year_OOS.AAER_DUMMY\n",
    "            \n",
    "            n_P=np.sum(Y_OOS==1)\n",
    "            n_N=np.sum(Y_OOS==0)\n",
    "            \n",
    "            scaling = MinMaxScaler(feature_range=(-1,1)).fit(X)\n",
    "            X = scaling.transform(X)\n",
    "            X_OOS = scaling.transform(X_OOS)\n",
    "            \n",
    "            \n",
    "            base_tree=DecisionTreeClassifier(min_samples_leaf=5)\n",
    "            bao_RUSboost=RUSBoostClassifier(base_estimator=base_tree,n_estimators=n_opt_rus,\\\n",
    "                             learning_rate=r_opt_rus,sampling_strategy=1,random_state=0)\n",
    "            clf_rusboost = bao_RUSboost.fit(X,Y)\n",
    "            \n",
    "            probs_oos_fraud_rusboost=clf_rusboost.predict_proba(X_OOS)[:,-1]\n",
    "            \n",
    "            labels_rusboost=clf_rusboost.predict(X_OOS)\n",
    "            \n",
    "            roc_rusboost[m]=roc_auc_score(Y_OOS,probs_oos_fraud_rusboost)\n",
    "            specificity_rusboost[m]=np.sum(np.logical_and(labels_rusboost==0,Y_OOS==0))/\\\n",
    "                np.sum(Y_OOS==0)\n",
    "            \n",
    "            sensitivity_OOS_rusboost[m]=np.sum(np.logical_and(labels_rusboost==1, \\\n",
    "                                                         Y_OOS==1))/np.sum(Y_OOS)\n",
    "            precision_rusboost[m]=np.sum(np.logical_and(labels_rusboost==1,Y_OOS==1))/np.sum(labels_rusboost)\n",
    "            \n",
    "            \n",
    "            cutoff_OOS_rusboost=np.percentile(probs_oos_fraud_rusboost,99)\n",
    "            sensitivity_OOS_rusboost1[m]=np.sum(np.logical_and(probs_oos_fraud_rusboost>=cutoff_OOS_rusboost, \\\n",
    "                                                         Y_OOS==1))/np.sum(Y_OOS)\n",
    "            specificity_OOS_rusboost1[m]=np.sum(np.logical_and(probs_oos_fraud_rusboost<cutoff_OOS_rusboost, \\\n",
    "                                                          Y_OOS==0))/np.sum(Y_OOS==0)\n",
    "            precision_rusboost1[m]=np.sum(np.logical_and(probs_oos_fraud_rusboost>=cutoff_OOS_rusboost, \\\n",
    "                                                         Y_OOS==1))/np.sum(probs_oos_fraud_rusboost>=cutoff_OOS_rusboost)\n",
    "            ndcg_rusboost1[m]=ndcg_k(Y_OOS,probs_oos_fraud_rusboost,99)\n",
    "            \n",
    "            FN_rusboost1=np.sum(np.logical_and(probs_oos_fraud_rusboost<cutoff_OOS_rusboost, \\\n",
    "                                                          Y_OOS==1))\n",
    "            FP_rusboost1=np.sum(np.logical_and(probs_oos_fraud_rusboost>=cutoff_OOS_rusboost, \\\n",
    "                                                          Y_OOS==0))\n",
    "                \n",
    "            ecm_rusboost1[m]=C_FN*P_f*FN_rusboost1/n_P+C_FP*P_nf*FP_rusboost1/n_N\n",
    "            \n",
    "            \n",
    "            t2=datetime.now() \n",
    "            dt=t2-t1\n",
    "            print('analysis finished for OOS period '+str(yr)+' after '+str(dt.total_seconds())+' sec')\n",
    "            m+=1\n",
    "\n",
    "        print('average top percentile sensitivity for the period '+str(start_OOS_year)+' to '+\\\n",
    "              str(end_OOS_year)+' is '+str(round(np.mean(sensitivity_OOS_rusboost1)*100,2))+\\\n",
    "                  '% for RUSBoost-28')\n",
    "\n",
    "        # create performance table now\n",
    "        perf_tbl_general=pd.DataFrame()\n",
    "        perf_tbl_general['models']=['RUS28_kfold']\n",
    "\n",
    "        perf_tbl_general['Roc']=str(np.round(\n",
    "            np.mean(roc_rusboost)*100,2))+'% ('+\\\n",
    "            str(np.round(np.std(roc_rusboost)*100,2))+'%)'\n",
    "        \n",
    "        perf_tbl_general['Roc_noise_to_signal']=str(np.round(\n",
    "            np.std(roc_rusboost)/np.mean(roc_rusboost)*100,2))+'%'\n",
    "                                                    \n",
    "        perf_tbl_general['Sensitivity @ 1 Prc']=str(np.round(\n",
    "            np.mean(sensitivity_OOS_rusboost1)*100,2))+'% ('+\\\n",
    "            str(np.round(np.std(sensitivity_OOS_rusboost1)*100,2))+'%)'\n",
    "        \n",
    "        perf_tbl_general['Sensitivity_noise_to_signal @ 1 Prc']=str(np.round(\n",
    "            np.std(sensitivity_OOS_rusboost1)/np.mean(sensitivity_OOS_rusboost1)*100,2))+'%'\n",
    "\n",
    "        perf_tbl_general['Specificity @ 1 Prc']=str(np.round(\n",
    "            np.mean(specificity_OOS_rusboost1)*100,2))+'% ('+\\\n",
    "            str(np.round(np.std(specificity_OOS_rusboost1)*100,2))+'%)'\n",
    "        \n",
    "        perf_tbl_general['Specificity_noise_to_signal @ 1 Prc']=str(np.round(\n",
    "            np.std(specificity_OOS_rusboost1)/np.mean(specificity_OOS_rusboost1)*100,2))+'%'\n",
    "        \n",
    "\n",
    "        perf_tbl_general['Precision @ 1 Prc']=str(np.round(\n",
    "            np.mean(precision_rusboost1)*100,2))+'% ('+\\\n",
    "            str(np.round(np.std(precision_rusboost1)*100,2))+'%)'\n",
    "        \n",
    "        perf_tbl_general['Precision_noise_to_signal @ 1 Prc']=str(np.round(\n",
    "            np.std(precision_rusboost1)/np.mean(precision_rusboost1)*100,2))+'%'\n",
    "        \n",
    "        f1_score_rusboost1=2*(precision_rusboost1*sensitivity_OOS_rusboost1)/\\\n",
    "            (precision_rusboost1+sensitivity_OOS_rusboost1+1e-8)\n",
    "        \n",
    "        perf_tbl_general['F1 Score @ 1 Prc']=str(np.round(\n",
    "            np.mean(f1_score_rusboost1)*100,2))+'% ('+\\\n",
    "            str(np.round(np.std(f1_score_rusboost1)*100,2))+'%)'\n",
    "        \n",
    "        perf_tbl_general['F1 Score_noise_to_signal @ 1 Prc']=str(np.round(\n",
    "            np.std(f1_score_rusboost1)/np.mean(f1_score_rusboost1)*100,2))+'%'\n",
    "                                                    \n",
    "        perf_tbl_general['NDCG @ 1 Prc']=str(np.round(\n",
    "            np.mean(ndcg_rusboost1)*100,2))+'% ('+\\\n",
    "            str(np.round(np.std(ndcg_rusboost1)*100,2))+'%)'\n",
    "        \n",
    "        perf_tbl_general['NDCG_noise_to_signal @ 1 Prc']=str(np.round(\n",
    "            np.std(ndcg_rusboost1)/np.mean(ndcg_rusboost1)*100,2))+'%'\n",
    "\n",
    "        perf_tbl_general['ECM @ 1 Prc']=str(np.round(\n",
    "            np.mean(ecm_rusboost1)*100,2))+'% ('+\\\n",
    "            str(np.round(np.std(ecm_rusboost1)*100,2))+'%)'\n",
    "        \n",
    "        perf_tbl_general['ECM_noise_to_signal @ 1 Prc']=str(np.round(\n",
    "            np.std(ecm_rusboost1)/np.mean(ecm_rusboost1)*100,2))+'%'\n",
    "        \n",
    "                   \n",
    "        lbl_perf_tbl='perf_tbl_'+str(start_OOS_year)+'_'+str(end_OOS_year)+\\\n",
    "                    '_'+case_window+',OOS='+str(OOS_period)+',serial='+str(adjust_serial)+\\\n",
    "                        ',gap='+str(OOS_gap)+'_kfold_RUSBoost.csv'\n",
    "\n",
    "        if write==True:\n",
    "            perf_tbl_general.to_csv(lbl_perf_tbl,index=False)\n",
    "        print(perf_tbl_general)\n",
    "        t_last=datetime.now()\n",
    "        dt_total=t_last-t0\n",
    "        print('total run time is '+str(dt_total.total_seconds())+' sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcca062e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Module initiated successfully ...\n",
      "Procedures are: analyse_raw()\n",
      "analysis finished for OOS period 2001 after 5.139632 sec\n",
      "analysis finished for OOS period 2002 after 5.703513 sec\n",
      "analysis finished for OOS period 2003 after 6.344101 sec\n",
      "analysis finished for OOS period 2004 after 7.062975 sec\n",
      "analysis finished for OOS period 2005 after 7.628896 sec\n",
      "analysis finished for OOS period 2006 after 8.830884 sec\n",
      "analysis finished for OOS period 2007 after 9.541539 sec\n",
      "analysis finished for OOS period 2008 after 10.302172 sec\n",
      "analysis finished for OOS period 2009 after 10.553144 sec\n",
      "analysis finished for OOS period 2010 after 10.891895 sec\n",
      "average top percentile sensitivity for the period 2001 to 2010 is 2.71% for RUSBoost-28\n",
      "        models             Roc Roc_noise_to_signal Sensitivity @ 1 Prc  \\\n",
      "0  RUS28_kfold  63.12% (9.65%)              15.29%       2.71% (6.14%)   \n",
      "\n",
      "  Sensitivity_noise_to_signal @ 1 Prc Specificity @ 1 Prc  \\\n",
      "0                             226.32%      98.99% (0.01%)   \n",
      "\n",
      "  Specificity_noise_to_signal @ 1 Prc Precision @ 1 Prc  \\\n",
      "0                               0.01%     0.59% (1.18%)   \n",
      "\n",
      "  Precision_noise_to_signal @ 1 Prc F1 Score @ 1 Prc  \\\n",
      "0                           200.43%    0.94% (1.91%)   \n",
      "\n",
      "  F1 Score_noise_to_signal @ 1 Prc  NDCG @ 1 Prc NDCG_noise_to_signal @ 1 Prc  \\\n",
      "0                          202.77%  1.8% (4.39%)                      243.41%   \n",
      "\n",
      "      ECM @ 1 Prc ECM_noise_to_signal @ 1 Prc  \n",
      "0  23.69% (1.44%)                       6.09%  \n",
      "total run time is 82.08977 sec\n"
     ]
    }
   ],
   "source": [
    "a = ML_Fraud(sample_start = 1991,test_sample = range (2001,2011),OOS_per = 1,OOS_gap = 0,sampling = \"expanding\",adjust_serial = True,\n",
    "            cv_flag = False,cv_k = 10,write = True,IS_per = 10)\n",
    "a.analyse_raw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffebb082",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
